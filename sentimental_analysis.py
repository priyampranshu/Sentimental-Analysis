# -*- coding: utf-8 -*-
"""Sentimental analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sk4yDIex28mghW7HI3g-pylaygZZYZd8

Sentiment analysis is the process of determining the emotional tone or attitude expressed in a piece of text. In the context of reviews:

Positive Sentiment: Indicates a favorable or positive opinion, often associated with satisfaction or appreciation.

Negative Sentiment: Indicates a critical or unfavorable opinion, often associated with dissatisfaction or criticism.

Neutral Sentiment: Indicates a lack of strong positive or negative opinions. The text may be factual or not strongly inclined toward either positive or negative emotions.
"""

import pandas as pd
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Download the vader_lexicon resource
nltk.download('vader_lexicon')

# Create a SentimentIntensityAnalyzer instance
sentiments = SentimentIntensityAnalyzer()

# Load your dataset (replace 'your_data.csv' with your actual file name)
data = pd.read_csv('nyka_top_brands_cosmetics_product_reviews.csv')
print(data.head())

print(data.describe())

"""As this dataset is very large, it contains some missing values, so letâ€™s remove all the rows containing the missing values:"""

data = data.dropna()

data

"""## **Checking For Null Values**"""

data.isnull().sum()

"""# **Handling Missing Values**"""

default_value = 'not_verified'
data['review_label'] = data['review_label'].fillna(default_value)

mean_rating = data['review_rating'].mean()
data['review_rating'] = data['review_rating'].fillna(mean_rating)

data = data.dropna(subset=['review_text'])
data['review_text'] = data['review_text'].fillna('')

"""## **Min-Max scaling to normalize data**"""

from sklearn.preprocessing import MinMaxScaler

columns_to_normalize = ['mrp', 'price']


scaler = MinMaxScaler()


data[columns_to_normalize] = scaler.fit_transform(data[columns_to_normalize])

"""# **Decision Tree**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.tree import DecisionTreeClassifier, export_graphviz, plot_tree, export_text
from sklearn.metrics import accuracy_score
import graphviz
from IPython.display import Image

x = data[['brand_name', 'review_rating', 'is_a_buyer', 'pro_user', 'mrp', 'price', 'product_rating', 'product_rating_count']]
y = data['review_label'] # target as it contains true and false

data['review_label'].unique()

x = pd.get_dummies(x)

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)

# Create Decision Tree classifier object
clf = DecisionTreeClassifier(criterion='entropy', max_features='log2')

# Train Decision Tree Classifier
clf = clf.fit(X_train, y_train)

# Predict the response for the test dataset
y_pred = clf.predict(X_test)

# Calculate and print the accuracy of the model
accuracy = metrics.accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

import matplotlib.pyplot as plt
plt.figure(figsize=(100, 100))
plot_tree(clf, feature_names=x.columns, max_depth=3, filled=True);

from sklearn.metrics import confusion_matrix
import seaborn as sns

y_pred = clf.predict(X_test)

cm = confusion_matrix(y_test, y_pred)

cm

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""- The top-left element (14420) represents the True Negatives (TN).
- The top-right element (0) represents the False Positives (FP).
- The bottom-left element (0) represents the False Negatives (FN).
- The bottom-right element (3830) represents the True Positives (TP).

Sentiment Analysis of Product Reviews
The Score column of this dataset contains the ratings that customers have given to the product based on their experience with the product. So letâ€™s take a look at the rating breakdown to see how most customers rate the products they buy :
"""

ratings = data["product_rating"].value_counts()
numbers = ratings.index
quantity = ratings.values

custom_colors = ["skyblue", "yellowgreen", 'tomato', "blue", "red"]
plt.figure(figsize=(10, 8))
plt.pie(quantity, labels=numbers, colors=custom_colors)
central_circle = plt.Circle((0, 0), 0.5, color='white')
fig = plt.gcf()
fig.gca().add_artist(central_circle)
plt.rc('font', size=12)
plt.title("Distribution of Product Ratings", fontsize=20)
plt.show()

"""According to the figure above, more than half of people rated products they bought with 5 stars, which is good. Now, we going to add three more columns to this dataset as Positive, Negative, and Neutral by calculating the sentiment scores of the customer reviews mentioned in the Text column of the dataset:"""

sentiments = SentimentIntensityAnalyzer()
data["Positive"] = [sentiments.polarity_scores(i)["pos"] for i in data["review_text"]]
data["Negative"] = [sentiments.polarity_scores(i)["neg"] for i in data["review_text"]]
data["Neutral"] = [sentiments.polarity_scores(i)["neu"] for i in data["review_text"]]
print(data.head())

"""Now letâ€™s see how most people rated the products they bought"""

x = sum(data["Positive"])
y = sum(data["Negative"])
z = sum(data["Neutral"])

def sentiment_score(a, b, c):
    if (a>b) and (a>c):
        print("Positive ğŸ˜Š ")
    elif (b>a) and (b>c):
        print("Negative ğŸ˜  ")
    else:
        print("Neutral ğŸ™‚ ")
sentiment_score(x, y, z)

"""So, most people are neutral when submitting their experiences with the products they have purchased . Now letâ€™s see the total of all sentiment scores:"""

print("Positive: ", x)
print("Negative: ", y)
print("Neutral: ", z)

"""So we can say that most of the reviews of the products are neutral, as the total sentiment scores of Positive and Neural are much higher than Negative scores."""

unique_product_names = data['product_title'].unique()
print("Unique Product Names:")
print(unique_product_names)

df = data.groupby(['product_title']).count()

import pandas as pd
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from tabulate import tabulate
import matplotlib.pyplot as plt

# Download the vader_lexicon resource
nltk.download('vader_lexicon')

# Create a SentimentIntensityAnalyzer instance
sentiments = SentimentIntensityAnalyzer()

# Load your dataset (replace 'your_data.csv' with your actual file name)
data = pd.read_csv('nyka_top_brands_cosmetics_product_reviews.csv')

def analyze_sentiment_for_product(product_name):
    # Filter reviews for the specified product (case-insensitive)
    product_reviews = data[data['product_title'].str.lower() == product_name.lower()]

    if product_reviews.empty:
        print(f"No reviews found for {product_name}.")
        return

    # Perform sentiment analysis on the reviews
    product_reviews["Positive"] = [sentiments.polarity_scores(i)["pos"] for i in product_reviews["review_text"]]
    product_reviews["Negative"] = [sentiments.polarity_scores(i)["neg"] for i in product_reviews["review_text"]]
    product_reviews["Neutral"] = [sentiments.polarity_scores(i)["neu"] for i in product_reviews["review_text"]]

    # Display sentiment analysis results for the specified product
    print(tabulate(product_reviews.head(), headers='keys', tablefmt='pretty'))

    # Pie chart for distribution of sentiments
    sentiments_distribution(product_reviews, product_name)

    # Calculate overall sentiment score
    x = sum(product_reviews["Positive"])
    y = sum(product_reviews["Negative"])
    z = sum(product_reviews["Neutral"])

    # Print overall sentiment score
    sentiment_score(x, y, z)

def sentiments_distribution(product_reviews, product_name):
    ratings = product_reviews["product_rating"].value_counts()
    numbers = ratings.index
    quantity = ratings.values

    custom_colors = ["skyblue", "yellowgreen", 'tomato', "blue", "red"]
    plt.figure(figsize=(10, 8))
    plt.pie(quantity, labels=numbers, colors=custom_colors)
    central_circle = plt.Circle((0, 0), 0.5, color='white')
    fig = plt.gcf()
    fig.gca().add_artist(central_circle)
    plt.rc('font', size=12)
    plt.title(f"Distribution of {product_name} Ratings", fontsize=20)
    plt.show()

def sentiment_score(a, b, c):
    if (a > b) and (a > c):
        print("Positive ğŸ˜Š ")
    elif (b > a) and (b > c):
        print("Negative ğŸ˜  ")
    else:
        print("Neutral ğŸ™‚ ")

# Example: Analyze sentiment for a specific product
analyze_sentiment_for_product('Kay Beauty Nail Nourish Nail Enamel Polish')

